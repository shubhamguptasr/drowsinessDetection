{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shubhamguptasr/drowsinessDetection/blob/main/Drowsiness_Detection_Original.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction.\n",
        "\n",
        "##### MRL Eye Dataset was created by xyz. Give a short summary of what the code is doing and the final results."
      ],
      "metadata": {
        "id": "zXWJ-LXrPQi9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "6PMc5C15KZOi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Flatten, Conv2D, MaxPooling2D, AvgPool2D, BatchNormalization\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "metadata": {
        "id": "ezyzMO7BKPT-"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import MRL Eye Dataset from Web \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "drso45sTrCQn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLRrYufII9Os",
        "outputId": "6303fa4c-ed95-4d86-a075-8b7cdeddc2a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-21 00:12:12--  http://mrl.cs.vsb.cz/data/eyedataset/mrlEyes_2018_01.zip\n",
            "Resolving mrl.cs.vsb.cz (mrl.cs.vsb.cz)... 158.196.141.22\n",
            "Connecting to mrl.cs.vsb.cz (mrl.cs.vsb.cz)|158.196.141.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 341866898 (326M) [application/zip]\n",
            "Saving to: ‘mrlEyes_2018_01.zip’\n",
            "\n",
            "mrlEyes_2018_01.zip 100%[===================>] 326.03M  5.54MB/s    in 56s     \n",
            "\n",
            "2023-03-21 00:13:12 (5.80 MB/s) - ‘mrlEyes_2018_01.zip’ saved [341866898/341866898]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://mrl.cs.vsb.cz/data/eyedataset/mrlEyes_2018_01.zip\n",
        "!unzip -q mrlEyes_2018_01.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sparse Data into labelled Open & Closed Images  "
      ],
      "metadata": {
        "id": "1oUKzXLYJ3dh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#function to bucket open & close into different folders given a sample \n",
        "def bucket_Open_close_Image(path,open_dir,close_dir):\n",
        "\n",
        "  print('Inside function : '+path)\n",
        "  #print('Inside function : '+open_dir)\n",
        "  #print('Inside function : '+close_dir)\n",
        "   \n",
        "  #creating new folders \n",
        "  Path(open_dir).mkdir(parents=True, exist_ok=True)\n",
        "  Path(close_dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "  with os.scandir(path) as entries:\n",
        "      for entry in entries:\n",
        "          if entry.is_file():\n",
        "              #print(entry.name)                         \n",
        "              open_close_indicator=entry.name.split(\"_\")[4]          \n",
        "              if open_close_indicator == '0':\n",
        "                #print('Eyes close'+entry.name)\n",
        "                try:\n",
        "                  shutil.copy(entry,close_dir)\n",
        "                except shutil.SameFileError:\n",
        "                  pass                  \n",
        "              elif open_close_indicator == '1':\n",
        "                #print('Eyes open'+entry.name)                \n",
        "                try:\n",
        "                  shutil.copy(entry, open_dir)\n",
        "                except shutil.SameFileError:\n",
        "                  pass    \n",
        "              else:\n",
        "                print('Outlier found -non -labelled data '+entry.name)"
      ],
      "metadata": {
        "id": "4IX1-U3LK-f5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function to bucket the images  open & close  with subcategories \n",
        "# 1. glasses 2.reflections 3.lighting conditions/image quality)\n",
        "\n",
        "#function to bucket open & close into different folders given a sample \n",
        "def bucket_Open_close_Image_into_subcategories(path,open_dir,close_dir):\n",
        "\n",
        "  #print('Inside function : '+path)\n",
        "  #print('Inside function : '+open_dir)\n",
        "  #print('Inside function : '+close_dir)\n",
        "   \n",
        "  #creating parent folders\n",
        "  Path(open_dir).mkdir(parents=True, exist_ok=True)\n",
        "  Path(close_dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "  #creating sub category folders for open\n",
        "  open_glass_on =open_dir+'/glass_yes'\n",
        "  open_glass_off =open_dir+'/glass_no'\n",
        "  open_relection_none =open_dir+'/reflection_none'\n",
        "  open_relection_low =open_dir+'/reflection_low'\n",
        "  open_relection_high =open_dir+'/reflection_high'\n",
        "  open_imagequality_bad =open_dir+'/imagequality_bad'\n",
        "  open_imagequality_good =open_dir+'/imagequality_good'\n",
        "\n",
        "  Path(open_glass_on).mkdir(exist_ok=True)\n",
        "  Path(open_glass_off).mkdir( exist_ok=True)\n",
        "  Path(open_relection_none).mkdir( exist_ok=True)\n",
        "  Path(open_relection_low).mkdir( exist_ok=True)\n",
        "  Path(open_relection_high).mkdir( exist_ok=True)\n",
        "  Path(open_imagequality_bad).mkdir( exist_ok=True)\n",
        "  Path(open_imagequality_good).mkdir( exist_ok=True)\n",
        "\n",
        "\n",
        "  #creating sub category folders for close\n",
        "  close_glass_on =close_dir+'/glass_yes'\n",
        "  close_glass_off =close_dir+'/glass_no'\n",
        "  close_relection_none =close_dir+'/reflection_none'\n",
        "  close_relection_low =close_dir+'/reflection_low'\n",
        "  close_relection_high =close_dir+'/reflection_high'\n",
        "  close_imagequality_bad =close_dir+'/imagequality_bad'\n",
        "  close_imagequality_good =close_dir+'/imagequality_good'\n",
        "\n",
        "  Path(close_glass_on).mkdir(exist_ok=True)\n",
        "  Path(close_glass_off).mkdir( exist_ok=True)\n",
        "  Path(close_relection_none).mkdir( exist_ok=True)\n",
        "  Path(close_relection_low).mkdir( exist_ok=True)\n",
        "  Path(close_relection_high).mkdir( exist_ok=True)\n",
        "  Path(close_imagequality_bad).mkdir( exist_ok=True)\n",
        "  Path(close_imagequality_good).mkdir( exist_ok=True)\n",
        "\n",
        "\n",
        "  with os.scandir(path) as entries:\n",
        "      for entry in entries:\n",
        "          if entry.is_file():\n",
        "              #print(entry.name)                         \n",
        "            \n",
        "              glass_indicator=entry.name.split(\"_\")[3]\n",
        "              open_close_indicator=entry.name.split(\"_\")[4]\n",
        "              relection_indicator=entry.name.split(\"_\")[5]\n",
        "              image_quality_indicator=entry.name.split(\"_\")[6]\n",
        "              try:                                        \n",
        "\n",
        "                  if open_close_indicator == '0':\n",
        "                    \n",
        "                  \n",
        "                    #bucketing subcategory glass\n",
        "                    if glass_indicator =='0':\n",
        "                      shutil.copy(entry,open_glass_off)\n",
        "                    elif glass_indicator =='1':\n",
        "                      shutil.copy(entry,open_glass_on)                \n",
        "\n",
        "                    #bucketing subcategory reflection\n",
        "                    if relection_indicator =='0':\n",
        "                      shutil.copy(entry,open_relection_none)\n",
        "                    elif relection_indicator =='1':\n",
        "                      shutil.copy(entry,open_relection_low)\n",
        "                    elif relection_indicator =='2':\n",
        "                      shutil.copy(entry,open_relection_high)\n",
        "\n",
        "                    #bucketing subcategory image quality\n",
        "                    if image_quality_indicator =='0':\n",
        "                      shutil.copy(entry,open_imagequality_bad)\n",
        "                    elif image_quality_indicator =='1':\n",
        "                      shutil.copy(entry,open_imagequality_good)\n",
        "                    \n",
        "                  elif open_close_indicator == '1':\n",
        "                    #print('Eyes open'+entry.name)                \n",
        "                    #bucketing subcategory glass\n",
        "                    if glass_indicator =='0':\n",
        "                      shutil.copy(entry,close_glass_off)\n",
        "                    elif glass_indicator =='1':\n",
        "                      shutil.copy(entry,close_glass_on)\n",
        "\n",
        "                    #bucketing subcategory reflection\n",
        "                    if relection_indicator =='0':\n",
        "                      shutil.copy(entry,close_relection_none)\n",
        "                    elif relection_indicator =='1':\n",
        "                      shutil.copy(entry,close_relection_low)\n",
        "                    elif relection_indicator =='2':\n",
        "                      shutil.copy(entry,close_relection_high)\n",
        "\n",
        "                    #bucketing subcategory image quality\n",
        "                    if image_quality_indicator =='0':\n",
        "                      shutil.copy(entry,close_imagequality_bad)\n",
        "                    elif image_quality_indicator =='1':\n",
        "                      shutil.copy(entry,close_imagequality_good)\n",
        "                  else:\n",
        "                    print('Outlier found -non -labelled data '+entry.name)\n",
        "              except shutil.SameFileError:\n",
        "                  pass \n",
        "\n"
      ],
      "metadata": {
        "id": "5J1ZTXl-63Yp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calling the function to bucket the data\n",
        "\n",
        "basepath = 'mrlEyes_2018_01/'\n",
        "#use the below two params to run with the funcion bucket_Open_close_Image\n",
        "#open_dir ='mrlEyes_2018_01/dataset/open'\n",
        "#close_dir ='mrlEyes_2018_01/dataset/close'\n",
        "\n",
        "#use the below two params to run with the funcion bucket_Open_close_Image_into_subcategories\n",
        "open_dir ='mrlEyes_2018_01/dataset_subcategory/open'\n",
        "close_dir ='mrlEyes_2018_01/dataset_subcategory/close'\n",
        "\n",
        "sampleData=[]\n",
        "for root, dirs, files in os.walk(basepath):\n",
        "    for dirname in dirs:\n",
        "        sampleData.append(os.path.join(root, dirname))\n",
        "print(sampleData)\n",
        "\n",
        " #clearing the existing folder and files if exists \n",
        "shutil.rmtree(open_dir,ignore_errors=True)\n",
        "shutil.rmtree(close_dir,ignore_errors=True)\n",
        "\n",
        "for path in sampleData:\n",
        "    bucket_Open_close_Image_into_subcategories(path,open_dir,close_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjOt91Ns5Gmx",
        "outputId": "b72463c6-92d9-4e6a-81b1-7544b4e18abf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['mrlEyes_2018_01/s0037', 'mrlEyes_2018_01/s0029', 'mrlEyes_2018_01/s0022', 'mrlEyes_2018_01/s0025', 'mrlEyes_2018_01/s0015', 'mrlEyes_2018_01/s0036', 'mrlEyes_2018_01/s0032', 'mrlEyes_2018_01/s0020', 'mrlEyes_2018_01/s0016', 'mrlEyes_2018_01/s0005', 'mrlEyes_2018_01/s0004', 'mrlEyes_2018_01/s0031', 'mrlEyes_2018_01/s0035', 'mrlEyes_2018_01/s0023', 'mrlEyes_2018_01/s0010', 'mrlEyes_2018_01/s0030', 'mrlEyes_2018_01/s0027', 'mrlEyes_2018_01/s0007', 'mrlEyes_2018_01/s0024', 'mrlEyes_2018_01/s0006', 'mrlEyes_2018_01/s0003', 'mrlEyes_2018_01/s0026', 'mrlEyes_2018_01/s0034', 'mrlEyes_2018_01/s0001', 'mrlEyes_2018_01/s0011', 'mrlEyes_2018_01/s0033', 'mrlEyes_2018_01/s0019', 'mrlEyes_2018_01/s0012', 'mrlEyes_2018_01/s0014', 'mrlEyes_2018_01/s0013', 'mrlEyes_2018_01/s0028', 'mrlEyes_2018_01/s0008', 'mrlEyes_2018_01/s0002', 'mrlEyes_2018_01/s0017', 'mrlEyes_2018_01/s0018', 'mrlEyes_2018_01/s0009', 'mrlEyes_2018_01/s0021']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check Number of Labelled Images"
      ],
      "metadata": {
        "id": "G8vl5Dc1LZag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "#use this when bucketing w/o sub categories\n",
        "open_dir ='mrlEyes_2018_01/dataset/open'\n",
        "close_dir ='mrlEyes_2018_01/dataset/close'\n",
        "\n",
        "#use this when bucketing with  sub categories\n",
        "#open_dir ='mrlEyes_2018_01/dataset_subcategory/open'\n",
        "#close_dir ='mrlEyes_2018_01/dataset_subcategory/close'\n",
        "\n",
        "for dir,subdir,files in os.walk(open_dir):  \n",
        "    print(dir  + \" has total number of files :\" + str(len(files)))\n",
        "\n",
        "print ('---------------------------------------------------------------------------------------------')\n",
        "for dir,subdir,files in os.walk(close_dir):  \n",
        "    print(dir  + \" has total number of files :\" + str(len(files))) \n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2nGD4CoVLTn",
        "outputId": "f777fbb5-6832-432e-9d10-e34e91cc66df"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Split"
      ],
      "metadata": {
        "id": "8C82YjLCL5_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(validation_split=0.2)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(directory = \"mrlEyes_2018_01/dataset_subcategory\", \n",
        "                                                     target_size=(32,32),\n",
        "                                                     batch_size=32,\n",
        "                                                     shuffle=True,\n",
        "                                                     class_mode='categorical',\n",
        "                                                     subset='training')\n",
        "\n",
        "validation_datagen = ImageDataGenerator(validation_split=0.2)\n",
        "validation_generator =  validation_datagen.flow_from_directory(directory = \"mrlEyes_2018_01/dataset_subcategory\", \n",
        "                                                                target_size=(32,32),\n",
        "                                                                batch_size=32,\n",
        "                                                                class_mode='categorical',\n",
        "                                                                subset='validation')   "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQWQXIEFMHhu",
        "outputId": "d741fdef-6f68-4c77-8077-84bd70abfb8c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 203756 images belonging to 2 classes.\n",
            "Found 50938 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator.class_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szdSHeMQMMAP",
        "outputId": "67441d4f-b694-4721-f1d3-e29fa175d03e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'close': 0, 'open': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create CNN Model"
      ],
      "metadata": {
        "id": "cMRqkHiGMO7l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model = Sequential([\n",
        "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(32,32,3)),\n",
        "    MaxPooling2D(pool_size=(1,1)),\n",
        "    Conv2D(32,(3,3),activation='relu'),\n",
        "    MaxPooling2D(pool_size=(1,1)),\n",
        "#32 convolution filters used each of size 3x3\n",
        "#again\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(1,1)),\n",
        "\n",
        "#64 convolution filters used each of size 3x3\n",
        "#choose the best features via pooling\n",
        "    \n",
        "#randomly turn neurons on and off to improve convergence\n",
        "    Dropout(0.25),\n",
        "#flatten since too many dimensions, we only want a classification output\n",
        "    Flatten(),\n",
        "#fully connected to get all relevant data\n",
        "    Dense(128, activation='relu'),\n",
        "#one more dropout for convergence' sake :) \n",
        "#    Dropout(0.5),\n",
        "#output a softmax to squash the matrix into output probabilities\n",
        "    Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "cnn_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Buen0XuKMSne",
        "outputId": "d76ca3af-8997-45f2-dc70-544dba65bc5d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 30, 30, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 30, 30, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 28, 28, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 28, 28, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 26, 26, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 26, 26, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 26, 26, 64)        0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 43264)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               5537920   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 258       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,566,818\n",
            "Trainable params: 5,566,818\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Compliation"
      ],
      "metadata": {
        "id": "X_KmVHrFMgIH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=[tf.keras.metrics.CategoricalAccuracy(),tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n"
      ],
      "metadata": {
        "id": "e_W6ec28MlnF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training"
      ],
      "metadata": {
        "id": "y8vb5K8hMryJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = cnn_model.fit(train_generator, validation_data=validation_generator, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WeOnKaU-MuHb",
        "outputId": "785fd63f-50c4-4fab-ede8-1b31a47b99e6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "6368/6368 [==============================] - 115s 16ms/step - loss: 0.2711 - categorical_accuracy: 0.9512 - precision: 0.9512 - recall: 0.9512 - val_loss: 0.0523 - val_categorical_accuracy: 0.9822 - val_precision: 0.9822 - val_recall: 0.9822\n",
            "Epoch 2/10\n",
            "6368/6368 [==============================] - 97s 15ms/step - loss: 0.0568 - categorical_accuracy: 0.9807 - precision: 0.9807 - recall: 0.9807 - val_loss: 0.0344 - val_categorical_accuracy: 0.9893 - val_precision: 0.9893 - val_recall: 0.9893\n",
            "Epoch 3/10\n",
            "6368/6368 [==============================] - 97s 15ms/step - loss: 0.0379 - categorical_accuracy: 0.9874 - precision: 0.9874 - recall: 0.9874 - val_loss: 0.0246 - val_categorical_accuracy: 0.9915 - val_precision: 0.9915 - val_recall: 0.9915\n",
            "Epoch 4/10\n",
            "6368/6368 [==============================] - 96s 15ms/step - loss: 0.0337 - categorical_accuracy: 0.9887 - precision: 0.9887 - recall: 0.9887 - val_loss: 0.0182 - val_categorical_accuracy: 0.9941 - val_precision: 0.9941 - val_recall: 0.9941\n",
            "Epoch 5/10\n",
            "6368/6368 [==============================] - 97s 15ms/step - loss: 0.0244 - categorical_accuracy: 0.9919 - precision: 0.9919 - recall: 0.9919 - val_loss: 0.0181 - val_categorical_accuracy: 0.9936 - val_precision: 0.9936 - val_recall: 0.9936\n",
            "Epoch 6/10\n",
            "6368/6368 [==============================] - 97s 15ms/step - loss: 0.0219 - categorical_accuracy: 0.9930 - precision: 0.9930 - recall: 0.9930 - val_loss: 0.0105 - val_categorical_accuracy: 0.9962 - val_precision: 0.9962 - val_recall: 0.9962\n",
            "Epoch 7/10\n",
            "6368/6368 [==============================] - 96s 15ms/step - loss: 0.0207 - categorical_accuracy: 0.9936 - precision: 0.9936 - recall: 0.9936 - val_loss: 0.0112 - val_categorical_accuracy: 0.9963 - val_precision: 0.9963 - val_recall: 0.9963\n",
            "Epoch 8/10\n",
            "6368/6368 [==============================] - 96s 15ms/step - loss: 0.0194 - categorical_accuracy: 0.9940 - precision: 0.9940 - recall: 0.9940 - val_loss: 0.0104 - val_categorical_accuracy: 0.9966 - val_precision: 0.9966 - val_recall: 0.9966\n",
            "Epoch 9/10\n",
            "6368/6368 [==============================] - 97s 15ms/step - loss: 0.0188 - categorical_accuracy: 0.9945 - precision: 0.9945 - recall: 0.9945 - val_loss: 0.0090 - val_categorical_accuracy: 0.9969 - val_precision: 0.9969 - val_recall: 0.9969\n",
            "Epoch 10/10\n",
            "6368/6368 [==============================] - 96s 15ms/step - loss: 0.0187 - categorical_accuracy: 0.9948 - precision: 0.9948 - recall: 0.9948 - val_loss: 0.0221 - val_categorical_accuracy: 0.9940 - val_precision: 0.9940 - val_recall: 0.9940\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plots"
      ],
      "metadata": {
        "id": "yvIUwryZO5zS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig1 = plt.gcf()\n",
        "plt.plot(history.history['categorical_accuracy'])\n",
        "plt.plot(history.history['val_categorical_accuracy'])\n",
        "plt.axis(ymin=0.4,ymax=1)\n",
        "plt.grid()\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend(['train', 'validation'])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "buwwukU8O8Z2",
        "outputId": "3a7a21ff-a44e-490b-b3ab-0b85881a6bd8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation"
      ],
      "metadata": {
        "id": "IB66o_6-NBn8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Elq_TL3BNEzD"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Z8EccQK0NKlc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "FhQWDUwOJ3MQ"
      }
    }
  ]
}